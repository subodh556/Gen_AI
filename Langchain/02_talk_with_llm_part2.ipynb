{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv , find_dotenv\n",
    "\n",
    "_ =load_dotenv(find_dotenv())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts and prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a curious story about the Kennedy family:\n",
      "\n",
      "**The Mysterious Disappearance of Rosemary Kennedy**\n",
      "\n",
      "Rosemary Kennedy, the third child and first daughter of Joseph P. Kennedy Sr. and Rose Fitzgerald Kennedy, was born in 1918. Growing up, Rosemary was known to be a sweet and gentle soul, but she struggled with intellectual disabilities and learning difficulties. Despite her challenges, Rosemary was a beloved member of the Kennedy family and was particularly close to her siblings, including John F. Kennedy, who would later become the President of the United States.\n",
      "\n",
      "In 1941, when Rosemary was 23 years old, her parents, desperate to \"cure\" her of her disabilities, made a fateful decision. They arranged for Rosemary to undergo a prefrontal lobotomy, a then-experimental procedure that involved severing connections in the brain in an attempt to alleviate mental health issues. The operation was performed by two inexperienced doctors, who carried out the procedure without the family's full understanding of its risks and consequences.\n",
      "\n",
      "The lobotomy was a disaster. It left Rosemary severely disabled, unable to speak or walk, and with a significant decline in her cognitive abilities. The Kennedy family was devastated by the outcome, and Rosemary was eventually placed in a Catholic institution in Wisconsin, where she lived for the rest of her life, largely hidden from public view.\n",
      "\n",
      "Here's the curious part: after the lobotomy, the Kennedy family effectively erased Rosemary from their public lives. They rarely spoke about her, and she was not included in family gatherings or events. It was as if she had disappeared. The family's silence about Rosemary's fate has been attributed to the stigma surrounding mental illness at the time, as well as the family's desire to maintain a perfect public image.\n",
      "\n",
      "In recent years, however, the Kennedy family has begun to acknowledge Rosemary's story and legacy. In 2015, the Kennedy family donated Rosemary's papers and memorabilia to the John F. Kennedy Presidential Library and Museum, and in 2017, a book titled \"Rosemary: The Forgotten Kennedy Daughter\" was published, shedding light on her life and struggles.\n",
      "\n",
      "Rosemary's story serves as a poignant reminder of the importance of understanding and supporting individuals with disabilities, as well as the need to confront and learn from our mistakes, even if they are painful and difficult to acknowledge.\n",
      "\n",
      "I hope you found this story curious and intriguing!\n"
     ]
    }
   ],
   "source": [
    "# for completion model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "tem = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}\"\n",
    ")\n",
    "chatm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "pro=tem.format(\n",
    "    adjective = \"curious\",\n",
    "    topic=\"The kennedy family\"\n",
    ")\n",
    "\n",
    "print(chatm.invoke(pro).content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 29 grandchildren. He had nine children with his wife Rose Fitzgerald Kennedy, and those children went on to have numerous offspring of their own. In fact, the Kennedy family is known for its large and sprawling family tree, with many descendants of Joseph and Rose still active in politics, business, and public life today.\n"
     ]
    }
   ],
   "source": [
    "# for chat completion model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "tem = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\",\"Hello, Mr.{profession}, can you please answer a question?\"),\n",
    "        (\"ai\",\"Sure!\"),\n",
    "        (\"human\",\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "chatm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "pro=tem.format_messages(\n",
    "    profession = \"historian\",\n",
    "    topic=\"The kennedy family\",\n",
    "    user_input=\"How many grandchildren has Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "print(chatm.invoke(pro).content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "exampl=[\n",
    "    {\"input\":\"hi\",\"output\":\"hola\"},\n",
    "    {\"input\":\"bye\",\"output\":\"adios\"}\n",
    "]\n",
    "\n",
    "proo = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"{input}\"),\n",
    "        (\"ai\",\"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=proo,\n",
    "    examples=exampl,\n",
    "\n",
    ")\n",
    "\n",
    "final = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an english-spanish translator\"),\n",
    "        few,\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Cómo estás?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "exampl=[\n",
    "    {\"input\":\"hi\",\"output\":\"hola\"},\n",
    "    {\"input\":\"bye\",\"output\":\"adios\"}\n",
    "]\n",
    "\n",
    "proo = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"{input}\"),\n",
    "        (\"ai\",\"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=proo,\n",
    "    examples=exampl,\n",
    "\n",
    ")\n",
    "\n",
    "final = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an english-spanish translator\"),\n",
    "        few,\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final | chatm\n",
    "\n",
    "chain.invoke({\"input\":\"How are you?\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Russia'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_p= PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question : {question}\"\n",
    ")\n",
    "json_pa = SimpleJsonOutputParser()\n",
    "json_ch = json_p | chatm | json_pa\n",
    "json_ch.invoke({\"question\":\"what is the biggest country\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally , you can use pydantic to define a custom output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a pydantic object with the desired output format.\n",
    "\n",
    "class joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline : str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the parser refering the pydantic object\n",
    "parser = SimpleJsonOutputParser(pydantic_object=joke)\n",
    "\n",
    "#Add the parset format instructions in the prompt definition.\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "#create a chain with the prompt and the parser\n",
    "chain = prompt | chatm | parser\n",
    "\n",
    "chain.invoke({\"query\":\"Tell me a joke.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
