{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv , find_dotenv\n",
    "\n",
    "_ =load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chatm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nLionel Messi has a growth hormone deficiency, which was diagnosed when he was just 11 years old. As a result, he had to undergo hormone therapy to help him grow. In fact, his family had to make huge sacrifices to pay for his treatment, which cost around $1,500 per month. This condition, combined with his small stature, made many coaches and scouts doubt his ability to succeed as a professional footballer. However, Messi's determination, hard work, and natural talent ultimately prevailed, and he went on to become one of the greatest footballers of all time!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | chatm | output_parser\n",
    "chain.invoke({\"soccer_player\":\"Lionel Messi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\n**Cristiano \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Builtin Functions\n",
    "#Use of .bind() to add arguments to a runnable in a LCEL chain\n",
    "\n",
    "chain = prompt | chatm.bind(stop=[\"Ronaldo\"]) | output_parser\n",
    "chain.invoke({\"soccer_player\":\"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What an amazing story! I'd definitely say that Lionel Messi is an inspiring and talented player! Despite facing a significant medical challenge, he overcame it with determination and hard work, and went on to achieve incredible success in his career. His rags-to-riches story is truly motivational, and it's wonderful to see how FC Barcelona's support helped him receive the necessary treatment. It just goes to show that with perseverance and the right support, anyone can achieve their dreams!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple chain\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "chain = prompt | chatm | output_parser\n",
    "\n",
    "#combining chain\n",
    "\n",
    "his_prompt = ChatPromptTemplate.from_template(\"was {soccer_player} player good or bad ?\")\n",
    "\n",
    "composed_chain = {\"soccer_player\":chain} | his_prompt | chatm | output_parser\n",
    "composed_chain.invoke({\"soccer_player\":\"Lionel Messi\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Une question facile !\\n\\nLa réponse est : L'Europe. François Mitterrand a été président de la France de 1981 à 1995, et la France est située sur le continent européen.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another example for combining chain\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"What is the country{politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"What continent is the country {country} in? respond in {language}\")\n",
    "\n",
    "chain1 = prompt1 | chatm | output_parser\n",
    "\n",
    "chain2 = ({\"country\":chain1,\"language\":itemgetter(\"language\")}) | prompt2 | chatm | output_parser\n",
    "\n",
    "chain2.invoke({\"politician\":\"Miterrand\",\"language\":\"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCEL Chain at work in a typical RAG app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.doument_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\",\"post-title\",\"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits,embeddings=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\":retriever | format_docs,\"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatm\n",
    "    | output_parser\n",
    ")\n",
    "rag_chain.invoke(\"What is task decomposition?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
